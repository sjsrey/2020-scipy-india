{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis of Spatial Data: Spatial Autocorrelation #\n",
    "\n",
    "\n",
    "In this notebook we introduce methods of _exploratory spatial data analysis_\n",
    "that are intended to complement geovizualization through formal univariate and\n",
    "multivariate statistical tests for spatial clustering.\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import esda\n",
    "import libpysal as lps\n",
    "import contextily as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context('notebook')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use two datasets:\n",
    "\n",
    "1. a set of polygons (census tracts) for the city of San Diego from the US Census American Community Survey 5-year estimates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scag = gpd.read_file(\"data/scag_region.gpkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego = scag[scag.geoid.str[:5]=='06073']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego = san_diego.dropna(subset=['median_home_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego = san_diego.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "san_diego.plot('median_home_value', ax=ax, alpha=0.6)\n",
    "cx.add_basemap(ax, crs=san_diego.crs.to_string(), source=cx.providers.Stamen.TonerLite)\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego.median_home_value.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "san_diego.dropna(subset=['median_home_value']).to_crs(epsg=3857).plot('median_home_value', legend=True, scheme='quantiles', cmap='GnBu', k=5, ax=ax, alpha=0.7)\n",
    "\n",
    "cx.add_basemap(ax, crs=san_diego.crs.to_string(), source=cx.providers.Stamen.TonerLite)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.title(\"Median Home Value (Quintiles)\", fontsize=16)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Autocorrelation ##\n",
    "\n",
    "Visual inspection of the map pattern for the prices allows us to search for\n",
    "spatial structure. If the spatial distribution of the prices was random, then we\n",
    "should not see any clustering of similar values on the map. However, our visual\n",
    "system is drawn to the darker clusters along the coast,\n",
    "and a concentration of the lighter hues (lower prices) in the north central and\n",
    "south east. In the point data, the trees are too dense to make any sense of the pattern\n",
    "\n",
    "Our brains are very powerful pattern recognition machines. However, sometimes\n",
    "they can be too powerful and lead us to detect false positives, or patterns\n",
    "where there are no statistical patterns. This is a particular concern when\n",
    "dealing with visualization of irregular polygons of differning sizes and shapes.\n",
    "\n",
    "The concept of *spatial\n",
    "autocorrelation* relates to the combination of two types of similarity: spatial\n",
    "similarity and attribute similarity. Although there are many different measures\n",
    "of spatial autocorrelation, they all combine these two types of simmilarity into\n",
    "a summary measure.\n",
    "\n",
    "Let's use PySAL to generate these two types of similarity\n",
    "measures.\n",
    "\n",
    "### Spatial Similarity ###\n",
    "\n",
    "We have already encountered spatial weights\n",
    "in a previous notebook. In spatial autocorrelation analysis, the spatial weights\n",
    "are used to formalize the notion of spatial similarity. As we have seen there\n",
    "are many ways to define spatial weights, here we will use queen contiguity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq =  lps.weights.Queen.from_dataframe(san_diego)\n",
    "wq.transform = 'r'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Similarity ###\n",
    "\n",
    "So the spatial weight between neighborhoods $i$ and $j$ indicates if the two \n",
    "are neighbors (i.e., geographically similar). What we also need is a measure of\n",
    "attribute similarity to pair up with this concept of spatial similarity. The\n",
    "**spatial lag** is a derived variable that accomplishes this for us. For neighborhood\n",
    "$i$ the spatial lag is defined as: $$ylag_i = \\sum_j w_{i,j} y_j$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = san_diego['median_home_value']\n",
    "ylag = lps.weights.lag_spatial(wq, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(12, 12))\n",
    "\n",
    "san_diego.assign(cl=ylag).plot(column='cl', scheme='quantiles', \\\n",
    "        k=5, cmap='GnBu', linewidth=0.1, ax=ax, \\\n",
    "        edgecolor='white', legend=True)\n",
    "\n",
    "cx.add_basemap(ax, crs=san_diego.crs.to_string(), source=cx.providers.Stamen.TonerLite)\n",
    "ax.axis('off')\n",
    "\n",
    "plt.title(\"Spatial Lag Median Home Val (Quintiles)\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quintile map for the spatial lag tends to enhance the impression of value\n",
    "similarity in space. It is, in effect, a local smoother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego['lag_median_pri'] = ylag\n",
    "\n",
    "f,ax = plt.subplots(1,2,figsize=(12,4))\n",
    "\n",
    "san_diego.plot(column='median_home_value', ax=ax[0],\n",
    "        scheme=\"quantiles\",  k=5, cmap='GnBu')\n",
    "\n",
    "#ax[0].axis(san_diego.total_bounds[np.asarray([0,2,1,3])])\n",
    "ax[0].set_title(\"Price\", fontsize=16)\n",
    "\n",
    "san_diego.plot(column='lag_median_pri', ax=ax[1],\n",
    "        scheme='quantiles', cmap='GnBu', k=5)\n",
    "\n",
    "cx.add_basemap(ax[0], crs=san_diego.crs.to_string(), source=cx.providers.Stamen.TonerLite)\n",
    "\n",
    "cx.add_basemap(ax[1], crs=san_diego.crs.to_string(), source=cx.providers.Stamen.TonerLite)\n",
    "\n",
    "ax[1].set_title(\"Spatial Lag Price\", fontsize=16)\n",
    "ax[0].axis('off')\n",
    "ax[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we still have\n",
    "the challenge of visually associating the value of the prices in a neighborhod\n",
    "with the value of the spatial lag of values for the focal unit. The latter is a\n",
    "weighted average of home prices in the focal county's neighborhood.\n",
    "\n",
    "To complement the geovisualization of these associations we can turn to formal\n",
    "statistical measures of spatial autocorrelation.\n",
    "\n",
    "\n",
    "## Global Spatial Autocorrelation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join counts ##\n",
    "\n",
    "One way to formalize a test for spatial autocorrelation in a binary attribute is\n",
    "to consider the so-called _joins_. A join exists for each neighbor pair of\n",
    "observations, and the joins are reflected in our binary spatial weights object\n",
    "`wq`. \n",
    "\n",
    "Each unit can take on one of two values \"Black\" or \"White\", analogous to the layout of a chessboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows, ncols = 9,9\n",
    "image = np.zeros(nrows*ncols)\n",
    "\n",
    "# Set every other cell to 1\n",
    "image[::2] = 1\n",
    "\n",
    "# Reshape things into a 9x9 grid.\n",
    "image = image.reshape((nrows, ncols))\n",
    "plt.matshow(image, cmap='Greys')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and so for a given\n",
    "pair of neighboring locations there are three different types of joins that can\n",
    "arise:\n",
    "\n",
    "- Black Black (BB)\n",
    "- White White (WW)\n",
    "- Black White (or White Black) (BW)\n",
    "\n",
    "\n",
    "We can use the `esda` package from PySAL to carry out join count analysis. In the case of our point data, the join counts can help us determine whether different varieties of trees tend to grow together, spread randomly through space, or compete with one another for precious resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polygon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With polygon data, we can conduct an analysis using a contiguity matrix. For our housing price data, we need to first discretize the variable we're using; to keep things simple, we'll binarize our price data using the median so that \"high\" values are tracts whose median home price is above the city's median and \"low\" values are those below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "san_diego.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = y > y.median()\n",
    "sum(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = y > y.median()\n",
    "labels = [\"0 Low\", \"1 High\"]\n",
    "yb = [labels[i] for i in 1*yb] \n",
    "san_diego['yb'] = yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "san_diego.plot(column='yb', cmap='binary', edgecolor='grey', legend=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spatial distribution of the binary variable immediately raises questions\n",
    "about the juxtaposition of the \"black\" and \"white\" areas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we have 308 Black polygons on our map, what is the number of Black\n",
    "Black (BB) joins we could expect if the process were such that the Black\n",
    "polygons were randomly assigned on the map?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb = 1 * (y > y.median()) # convert back to binary\n",
    "wq =  lps.weights.Queen.from_dataframe(san_diego)\n",
    "wq.transform = 'b'\n",
    "np.random.seed(12345)\n",
    "jc = esda.join_counts.Join_Counts(yb, wq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting object stores the observed counts for the different types of joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the three cases exhaust all possibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.bb + jc.ww + jc.bw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq.s0 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is the unique number of joins in the spatial weights object.\n",
    "\n",
    "Our object tells us we have observed 736 BB joins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critical question for us, is whether this is a departure from what we would\n",
    "expect if the process generating the spatial distribution of the Black polygons\n",
    "were a completely random one? To answer this, PySAL uses random spatial\n",
    "permutations of the observed attribute values to generate a realization under\n",
    "the null of _complete spatial randomness_ (CSR). This is repeated a large number\n",
    "of times (999 default) to construct a reference distribution to evaluate the\n",
    "statistical significance of our observed counts.\n",
    "\n",
    "The average number of BB joins from the synthetic realizations is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.mean_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is less than our observed count. The question is whether our observed\n",
    "value is so different from the expectation that we would reject the null of CSR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sbn\n",
    "sbn.kdeplot(jc.sim_bb.astype('float'), shade=True)\n",
    "plt.vlines(jc.bb, 0, 0.075, color='r')\n",
    "plt.vlines(jc.mean_bb, 0,0.075)\n",
    "plt.xlabel('BB Counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density portrays the distribution of the BB counts, with the black vertical\n",
    "line indicating the mean BB count from the synthetic realizations and the red\n",
    "line the observed BB count for our prices. Clearly our observed value is\n",
    "extremely high. A pseudo p-value summarizes this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jc.p_sim_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is below conventional significance levels, we would reject the null\n",
    "of complete spatial randomness in favor of spatial autocorrelation in market prices.\n",
    "\n",
    "\n",
    "### Continuous Case\n",
    "\n",
    "The join count analysis is based on a binary attribute, which can cover many\n",
    "interesting empirical applications where one is interested in presence and\n",
    "absence type phenomena. In our case, we artificially created the binary variable,\n",
    "and in the process we throw away a lot of information in our originally\n",
    "continuous attribute. Turning back to the original variable, we can explore\n",
    "other tests for spatial autocorrelation for the continuous case.\n",
    "\n",
    "First, we transform our weights to be row-standardized, from the current binary state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq.transform = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = san_diego['median_home_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moran's I is a test for global autocorrelation for a continuous attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "mi = esda.moran.Moran(y, wq)\n",
    "mi.I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, our value for the statistic needs to be interpreted against a reference\n",
    "distribution under the null of CSR. PySAL uses a similar approach as we saw in\n",
    "the join count analysis: random spatial permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import plot_moran\n",
    "plot_moran(mi, zstandard=True, figsize=(10,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the left, we have the reference distribution versus the observed statistic; on the right, we have a plot of the focal value against its spatial lag, for which the Moran I statistic serves as the slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our observed value is again in the upper tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Autocorrelation: Hot Spots, Cold Spots, and Spatial Outliers ##\n",
    "\n",
    "In addition to the Global autocorrelation statistics, PySAL has many local\n",
    "autocorrelation statistics. Let's compute a local Moran statistic for the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq.transform = 'r'\n",
    "lag_price = lps.weights.lag_spatial(wq, san_diego['median_home_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = esda.moran.Moran_Local(y, wq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of a single $I$ statistic, we have an *array* of local $I_i$\n",
    "statistics, stored in the `.Is` attribute, and p-values from the simulation are\n",
    "in `p_sim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import moran_scatterplot\n",
    "\n",
    "fig, ax = moran_scatterplot(li)\n",
    "ax.set_xlabel('Price')\n",
    "ax.set_ylabel('Spatial Lag of Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li.q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again test for local clustering using permutations, but here we use\n",
    "conditional random permutations (different distributions for each focal location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(li.p_sim < 0.05).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = moran_scatterplot(li, p=0.05)\n",
    "ax.set_xlabel('Price')\n",
    "ax.set_ylabel('Spatial Lag of Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can distinguish the specific type of local spatial association reflected in\n",
    "the four quadrants of the Moran Scatterplot above:\n",
    "- High-High (upper right)\n",
    "- Low-Low (bottom left)\n",
    "- High-Low (lower right)\n",
    "- Low-High (upper left)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `splot`, we can also plot these hotspots on the original geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import lisa_cluster\n",
    "lisa_cluster(li, san_diego, p=0.05, figsize = (9,9))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splot.esda import plot_local_autocorrelation\n",
    "plot_local_autocorrelation(li, san_diego, 'median_home_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
